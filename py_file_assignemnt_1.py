# -*- coding: utf-8 -*-
"""py-file-assignemnt-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cOBhiMnBTZqABc44MoO7t4NUYLZTYDvo
"""

import timeit
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.types import (
    StructType, StructField, StringType, IntegerType, DoubleType, TimestampType
)
from pyspark.sql.functions import lit, col, create_map
import random

def initialize_spark_session():
    """
    Initialize the Spark session with Iceberg configurations.
    """
    try:
        start_time = timeit.default_timer()
        spark = SparkSession.builder \
            .appName("IcebergLocalDevelopment") \
            .master("local[*]") \
            .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2') \
            .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
            .config("spark.sql.catalog.local", "org.apache.iceberg.spark.SparkCatalog") \
            .config("spark.sql.catalog.local.type", "hadoop") \
            .config("spark.sql.catalog.local.warehouse", "spark-warehouse/iceberg") \
            .getOrCreate()
        elapsed_time = timeit.default_timer() - start_time
        print(f"Spark session initialized in {elapsed_time:.2f} seconds.")
        return spark
    except Exception as e:
        print(f"Error initializing Spark session: {e}")
        return None

def read_dataset(spark, file_path):
    """
    Read JSON dataset from the given file path.
    """
    try:
        start_time = timeit.default_timer()
        df = spark.read.json(file_path)
        print(f"Dataset read successfully with {df.count()} rows and {len(df.columns)} columns.")
        df.show(10)
        elapsed_time = timeit.default_timer() - start_time
        print(f"Elapsed time for reading dataset: {elapsed_time:.2f} seconds.")
        return df
    except Exception as e:
        print(f"Error reading dataset: {e}")
        return None

def get_country_code_mapping():
    """
    Returns a dictionary containing country names as keys and their corresponding country codes as values.

    Returns:
        dict: A dictionary with country names as keys and country codes as values.
    """
    try:
        start_time = timeit.default_timer()
        country_code_mapping = {
            "Bonaire Saint Eustatius and Saba": "BQ",
            "Paraguay": "PY",
            "Anguilla": "AI",
            "Macao": "MO",
            "U.S. Virgin Islands": "VI",
            "Senegal": "SN",
            "Sweden": "SE",
            "Guyana": "GY",
            "Philippines": "PH",
            "Jersey": "JE",
            "Eritrea": "ER",
            "Djibouti": "DJ",
            "Norfolk Island": "NF",
            "Tonga": "TO",
            "Singapore": "SG",
            "Malaysia": "MY",
            "Fiji": "FJ",
            "Turkey": "TR",
            "Malawi": "MW",
            "Germany": "DE",
            "Northern Mariana Islands": "MP",
            "Comoros": "KM",
            "Cambodia": "KH",
            "Maldives": "MV",
            "Ivory Coast": "CI",
            "Jordan": "JO",
            "Rwanda": "RW",
            "Palau": "PW",
            "France": "FR",
            "Turks and Caicos Islands": "TC",
            "Greece": "GR",
            "Sri Lanka": "LK",
            "Montserrat": "MS",
            "Taiwan": "TW",
            "Dominica": "DM",
            "British Virgin Islands": "VG",
            "Algeria": "DZ",
            "Togo": "TG",
            "Equatorial Guinea": "GQ",
            "Slovakia": "SK",
            "Reunion": "RE",
            "Argentina": "AR",
            "Belgium": "BE",
            "Angola": "AO",
            "San Marino": "SM",
            "Ecuador": "EC",
            "Qatar": "QA",
            "Lesotho": "LS",
            "Albania": "AL",
            "Madagascar": "MG",
            "Finland": "FI",
            "New Caledonia": "NC",
            "Ghana": "GH",
            "Myanmar": "MM",
            "Nicaragua": "NI",
            "Guernsey": "GG",
            "Peru": "PE",
            "Benin": "BJ",
            "Sierra Leone": "SL",
            "United States": "US",
            "India": "IN",
            "Bahamas": "BS",
            "China": "CN",
            "Curacao": "CW",
            "Belarus": "BY",
            "Malta": "MT",
            "Kuwait": "KW",
            "Sao Tome and Principe": "ST",
            "Palestinian Territory": "PS",
            "Puerto Rico": "PR",
            "Chile": "CL",
            "Tajikistan": "TJ",
            "Martinique": "MQ",
            "Cayman Islands": "KY",
            "Isle of Man": "IM",
            "Croatia": "HR",
            "Burundi": "BI",
            "Nigeria": "NG",
            "Andorra": "AD",
            "Bolivia": "BO",
            "Gabon": "GA",
            "Italy": "IT",
            "Suriname": "SR",
            "Lithuania": "LT",
            "Norway": "NO",
            "Turkmenistan": "TM",
            "Spain": "ES",
            "Cuba": "CU",
            "Mauritania": "MR",
            "Guadeloupe": "GP",
            "Denmark": "DK",
            "Barbados": "BB",
            "Bangladesh": "BD",
            "Ireland": "IE",
            "Liechtenstein": "LI",
            "Swaziland": "SZ",
            "Thailand": "TH",
            "Laos": "LA",
            "Christmas Island": "CX",
            "Bhutan": "BT",
            "Democratic Republic of the Congo": "CD",
            "Morocco": "MA",
            "Monaco": "MC",
            "Panama": "PA",
            "Cape Verde": "CV",
            "Hong Kong": "HK",
            "Israel": "IL",
            "Iceland": "IS",
            "Saint Barthelemy": "BL",
            "Saint Kitts and Nevis": "KN",
            "Oman": "OM",
            "French Polynesia": "PF",
            "South Korea": "KR",
            "Cyprus": "CY",
            "Gibraltar": "GI",
            "Uruguay": "UY",
            "Mexico": "MX",
            "Aruba": "AW",
            "Montenegro": "ME",
            "Georgia": "GE",
            "Zimbabwe": "ZW",
            "Estonia": "EE",
            "Indonesia": "ID",
            "Saint Vincent and the Grenadines": "VC",
            "Guatemala": "GT",
            "Guam": "GU",
            "Mongolia": "MN",
            "Republic of the Congo": "CG",
            "Azerbaijan": "AZ",
            "Sint Maarten": "SX",
            "Grenada": "GD",
            "Armenia": "AM",
            "Tunisia": "TN",
            "Liberia": "LR",
            "Honduras": "HN",
            "Trinidad and Tobago": "TT",
            "Saudi Arabia": "SA",
            "Uganda": "UG",
            "Wallis and Futuna": "WF",
            "French Guiana": "GF",
            "Namibia": "NA",
            "Mayotte": "YT",
            "Switzerland": "CH",
            "Zambia": "ZM",
            "Ethiopia": "ET",
            "Jamaica": "JM",
            "Latvia": "LV",
            "United Arab Emirates": "AE",
            "Brunei": "BN",
            "Saint Lucia": "LC",
            "Saint Martin": "MF",
            "Aland Islands": "AX",
            "Guinea": "GN",
            "Canada": "CA",
            "Seychelles": "SC",
            "Kyrgyzstan": "KG",
            "Uzbekistan": "UZ",
            "Macedonia": "MK",
            "Faroe Islands": "FO",
            "Samoa": "WS",
            "Czech Republic": "CZ",
            "Mozambique": "MZ",
            "Cook Islands": "CK",
            "Brazil": "BR",
            "Belize": "BZ",
            "Kenya": "KE",
            "Gambia": "GM",
            "Lebanon": "LB",
            "Slovenia": "SI",
            "Antigua and Barbuda": "AG",
            "Dominican Republic": "DO",
            "Japan": "JP",
            "Tanzania": "TZ",
            "Botswana": "BW",
            "Luxembourg": "LU",
            "New Zealand": "NZ",
            "United States Minor Outlying Islands": "UM",
            "Bosnia and Herzegovina": "BA",
            "Greenland": "GL",
            "Haiti": "HT",
            "Poland": "PL",
            "Portugal": "PT",
            "Australia": "AU",
            "Cameroon": "CM",
            "Papua New Guinea": "PG",
            "Romania": "RO",
            "Guinea-Bissau": "GW",
            "Bulgaria": "BG",
            "Austria": "AT",
            "Nepal": "NP",
            "Egypt": "EG",
            "Costa Rica": "CR",
            "El Salvador": "SV",
            "Kazakhstan": "KZ",
            "Serbia": "RS",
            "South Africa": "ZA",
            "Burkina Faso": "BF",
            "Bermuda": "BM",
            "Bahrain": "BH",
            "Micronesia": "FM",
            "Colombia": "CO",
            "Hungary": "HU",
            "Pakistan": "PK",
            "Vanuatu": "VU",
            "Mauritius": "MU",
            "United Kingdom": "GB",
            "Moldova": "MD",
            "Vietnam": "VN",
            "Netherlands": "NL",
            "Mali": "ML",
            "Chad": "TD",
            "Svalbard and Jan Mayen": "SJ",
            "Sudan": "SD",
            "Niue": "NU",
            "Kiribati": "KI",
            "Iraq": "IQ",
            "American Samoa": "AS",
            "Saint Pierre and Miquelon": "PM",
            "Niger": "NE",
            "Solomon Islands": "SB"
        }
        elapsed_time = timeit.default_timer() - start_time
        print(f"Elapsed time for generating country code mapping: {elapsed_time:.2f} seconds.")
        return country_code_mapping
    except Exception as e:
        print(f"An error occurred while generating the country code mapping: {e}")
        return {}

def create_country_code_mapping(spark, country_code_mapping):
    """
    Create a DataFrame with country codes from the mapping.
    """
    try:
        start_time = timeit.default_timer()
        print("Creating country code mapping DataFrame...")
        data = [(country,) for country in country_code_mapping.keys()]
        df = spark.createDataFrame(data, ["Country"])
        mapping_expr = create_map([lit(x) for x in sum(country_code_mapping.items(), ())])
        df = df.withColumn("CountryCode", mapping_expr.getItem(col("Country")))
        print("Country code mapping DataFrame created successfully.")
        df.show(truncate=False)
        elapsed_time = timeit.default_timer() - start_time
        print(f"Elapsed time for creating country code mapping DataFrame: {elapsed_time:.2f} seconds.")
        return df, mapping_expr
    except Exception as e:
        print(f"Error creating country code mapping DataFrame: {e}")
        return None, None

def transform_dataframe(df, country_mapping_expr):
    """
    Transform the input DataFrame with required columns and mapping.
    """
    try:
        start_time = timeit.default_timer()
        transformed_df = df.select(
            F.when(F.col("propertyId.expedia").isNull(), F.lit('False'))
              .otherwise(F.col("propertyId.expedia").cast(IntegerType()))
              .alias("listing_source_site"),
          F.when(F.col("lastUpdated").isNull(), F.lit("' '"))
            .otherwise(F.to_timestamp("lastUpdated", "dd-MM-yyyy HH:mm:ss"))
            .alias("property_modified_date"),
            F.when(F.col("starRating").isNull(), F.lit("' '"))
              .otherwise(F.col("starRating").cast(StringType()))
              .alias("star_rating"),
            F.when(F.col("referencePrice.currency").isNull(), F.lit("' '"))
              .otherwise(F.col("referencePrice.currency"))
              .alias("currency"),
            F.when(F.col("referencePrice.value").isNull(), F.lit("' '"))
              .otherwise(F.col("referencePrice.value").cast(DoubleType()))
              .alias("usd_price"),
            F.struct(
                F.when(F.col("chainAndBrand.brandId").isNull(), F.concat(F.lit('"brand_id": '), F.lit("' '")))
                .otherwise(F.concat(F.lit('"brand_id": '), F.col("chainAndBrand.brandId").cast(IntegerType()))).alias("brand_id"),
                F.when(F.col("chainAndBrand.chainId").isNull(), F.concat(F.lit('"chain_id": '), F.lit("' '")))
                .otherwise(F.concat(F.lit('"chain_id": '), F.col("chainAndBrand.chainId").cast(IntegerType()))).alias("chain_id"),
                F.when(F.col("chainAndBrand.brandName").isNull(), F.concat(F.lit('"brand_name": '), F.lit("' '")))
                .otherwise(F.concat(F.lit('"brand_name": '), F.col("chainAndBrand.brandName").cast(StringType()))).alias("brand_name"),
                F.when(F.col("chainAndBrand.chainName").isNull(), F.concat(F.lit('"chain_name": '), F.lit("' '")))
                .otherwise(F.concat(F.lit('"chain_name": '), F.col("chainAndBrand.chainName").cast(StringType()))).alias("chain_name")
            ).alias("chain_and_brand"),
            F.col("country")
        )

        # Adding country_code after mapping
        transformed_df = transformed_df.withColumn("country_code", country_mapping_expr.getItem(F.col("country")))

        # Drop the original 'country' column
        transformed_df = transformed_df.drop("country")

        print("DataFrame transformed successfully.")
        transformed_df.show(20, truncate=False)
        elapsed_time = timeit.default_timer() - start_time
        print(f"Elapsed time for transforming DataFrame: {elapsed_time:.2f} seconds.")
        return transformed_df
    except Exception as e:
        print(f"Error transforming DataFrame: {e}")
        return None


def create_iceberg_table(spark):
    """
    Create the Iceberg table if it does not exist.
    """
    try:
      start_time = timeit.default_timer()
      spark.sql("DROP TABLE IF EXISTS local.siamdb.transformed_table")

      spark.sql(
          """
          CREATE TABLE IF NOT EXISTS local.siamdb.transformed_table (
              listing_source_site INT,
              property_modified_date STRING,
              star_rating STRING,
              currency STRING,
              usd_price STRING,
              chain_and_brand STRUCT<
                  brand_id: STRING,
                  chain_id: STRING,
                  brand_name: STRING,
                  chain_name: STRING
              >,
              country_code STRING
          )
          USING iceberg
          TBLPROPERTIES (
              'history.expire.max-snapshot-age-ms' = '60000',
              'write.format.default' = 'parquet'
          )
          PARTITIONED BY (country_code)
          """
      )
      elapsed_time = timeit.default_timer() - start_time
      print(f"Elapsed time for creating Iceberg table: {elapsed_time:.2f} seconds.")

    except Exception as e:
        print(f"Error creating Iceberg table: {e}")

def write_to_iceberg_table(spark,df):
    """
    Write the transformed DataFrame to the Iceberg table.
    """
    try:
        start_time = timeit.default_timer()
        df.write \
            .format("iceberg") \
            .mode("append") \
            .saveAsTable("local.siamdb.transformed_table")
        print("Data written to Iceberg table successfully.")

        df2 = spark.sql("SELECT * FROM local.siamdb.transformed_table")
        df2.show(5000,truncate=False)
        elapsed_time = timeit.default_timer() - start_time
        print(f"Elapsed time for writing to Iceberg table: {elapsed_time:.2f} seconds.")
    except Exception as e:
        print(f"Error writing to Iceberg table: {e}")

def main():
    # Initialize Spark session
    spark = initialize_spark_session()
    # Read dataset
    from google.colab import drive
    drive.mount("/content/drive")

    file_path = "/content/drive/MyDrive/Data-W3/expedia-lodging-listings-en_us-1-all.jsonl"
    df = read_dataset(spark, file_path)

    # Country code mapping
    country_codes = get_country_code_mapping()
    country_df, mapping_expr = create_country_code_mapping(spark, country_codes)

    # Transform DataFrame
    transformed_df = transform_dataframe(df, mapping_expr)


    transformed_df = transformed_df.withColumn("listing_source_site", transformed_df["listing_source_site"].cast(IntegerType()))

    # Create Iceberg table
    create_iceberg_table(spark)

    # Write to Iceberg table
    write_to_iceberg_table(spark,transformed_df)


if __name__ == "__main__":
    main()